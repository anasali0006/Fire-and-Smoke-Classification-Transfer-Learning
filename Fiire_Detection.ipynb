{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Improved Final .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPg/mlPQgtutju1GijVy8U7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anasali0006/Fire-and-Smoke-Detection-Transfer-Learning/blob/main/Fiire_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr4KoSB_9tiP"
      },
      "source": [
        "\n",
        "\n",
        "## 1.   Importing Google Drive into Colab \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aYmAEDTANUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e962c9e8-4558-4059-f5b4-30d69ba2c154"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYiSsrGs9-7L"
      },
      "source": [
        "# 2. Getting the Training Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkwg-PZqAT5e"
      },
      "source": [
        "!unzip -q /content/drive/'My Drive'/'FinalFire.zip' -d Fire\n",
        "!unzip -q /content/drive/'My Drive'/'FinalNonfire.zip' -d Fire"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_M6KW--GTe"
      },
      "source": [
        "## 3. Installing Tensorflow 2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOqI_U6-1rMA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "06980eb8-55e4-4a3f-8cf0-17d22a50f5a3"
      },
      "source": [
        "pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vx2t5SSh3QG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca020e83-6413-4dcc-ed61-b41f4566fa2d"
      },
      "source": [
        "pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 30kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/keras-applications/\u001b[0m\n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.32.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=bd5d401b0a09b19d2280003f2bfc34b2d9561c566a7fca31300b93f0dc24a196\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpI-GTdXiJX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ce1b75d-bc50-47fa-8f0e-c3af985006c9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Ct_tm0y-5p"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF3zXYY4-TE1"
      },
      "source": [
        "## 4. Loading the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyxzQJ7bAWo0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00441c0f-002d-48a2-9d7f-b2bfefb8c8ea"
      },
      "source": [
        "import cv2\n",
        "import sys\n",
        "from imutils import paths\n",
        "\n",
        "FIRE_PATH='/content/Fire/Fire'\n",
        "NON_FIRE_PATH='/content/Fire/Nonfire'\n",
        "\n",
        "def load_dataset(datasetPath):\n",
        "\t# grab the paths to all images in our dataset directory, then\n",
        "\t# initialize our lists of images\n",
        "\timagePaths = list(paths.list_images(datasetPath))\n",
        "\tdata = []\n",
        "\n",
        "\t# loop over the image paths\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\t# load the image and resize it to be a fixed 128x128 pixels,\n",
        "\t\t# ignoring aspect ratio\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.resize(image, (128,128))\n",
        "\n",
        "\t\t# add the image to the data lists\n",
        "\t\tdata.append(image)\n",
        "\n",
        "\t# return the data list as a NumPy array\n",
        "\treturn np.array(data, dtype=\"float32\")\n",
        "\n",
        "\n",
        "\n",
        "# load the fire and non-fire images\n",
        "print(\"[INFO] loading data...\")\n",
        "fireData = load_dataset( FIRE_PATH)\n",
        "nonFireData = load_dataset( NON_FIRE_PATH)\n",
        "print(\"[INFO] Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading data...\n",
            "[INFO] Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBCxZrG-Y_C"
      },
      "source": [
        "## 5. (CorssValidation)Test-Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOhcXeG5uNB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "efdcf682-da30-4187-8cae-0690629295a5"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# initialize the class labels in the dataset\n",
        "CLASSES = [\"Non-Fire\", \"Fire\"]\n",
        "\n",
        "# define the size of the training and testing split\n",
        "TRAIN_SPLIT = 0.90\n",
        "TEST_SPLIT = 0.10\n",
        "\n",
        "# define the initial learning rate, batch size, and number of epochs\n",
        "INIT_LR = 1e-2\n",
        "BATCH_SIZE = 100\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "\n",
        "SAMPLE_SIZE = 50\n",
        "\n",
        "\n",
        "print(fireData.shape)\n",
        "print(nonFireData.shape)\n",
        "\n",
        "\n",
        "\n",
        "# construct the class labels for the data\n",
        "fireLabels = np.ones((fireData.shape[0],))\n",
        "nonFireLabels = np.zeros((nonFireData.shape[0],))\n",
        "# stack the fire data with the non-fire data, then scale the data\n",
        "# to the range [0, 1]\n",
        "data = np.vstack([fireData, nonFireData])\n",
        "labels = np.hstack([fireLabels, nonFireLabels])\n",
        "\n",
        "\n",
        "\n",
        "data /= 255\n",
        "# perform one-hot encoding on the labels and account for skew in the\n",
        "# labeled data\n",
        "labels = to_categorical(labels, num_classes=2)\n",
        "classTotals = labels.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals\n",
        "\n",
        "\n",
        "\n",
        "# construct the training and testing split\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size= TEST_SPLIT, random_state=42)\n",
        "print(trainX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7553, 128, 128, 3)\n",
            "(3650, 128, 128, 3)\n",
            "(10082, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5suT2z-r-eIM"
      },
      "source": [
        "## 6. Observing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtJVxOfZjHKD"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
        "    if trainY[i][0] == 1:\n",
        "      plt.xlabel(\"Non-Fire\")\n",
        "    else:\n",
        "      plt.xlabel(\"Fire\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDMUJWNr-iSC"
      },
      "source": [
        "# 7. Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvxd_U-erGaY"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "base_model=Xception(include_top=False, input_shape=(128,128,3), weights='imagenet')\n",
        "base_model.trainable=False\n",
        "#print(base_model.summary())\n",
        "input_image=Input(shape=(128,128,3))\n",
        "x=base_model(input_image, training=False)\n",
        "\n",
        "x=Flatten()(x)\n",
        "x=keras.layers.Dense(2048,activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x=keras.layers.Dense(2048,activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x=keras.layers.Dense(1024,activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x=keras.layers.Dense(1024,activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x=keras.layers.Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = keras.layers.Dense(2, activation='softmax')(x)\n",
        "model = keras.Model(input_image, outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ivxCqF0toxq"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvTXGlC_-myS"
      },
      "source": [
        "# 8. This part is for Fine-Tuning after the Transfer Learning Model is trained on our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb-olfqGr8tj"
      },
      "source": [
        "NUM_EPOCHS=100\n",
        "INIT_LR=0.0001\n",
        "base_model.trainable=True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPnWHeRs-yXa"
      },
      "source": [
        "# 9. Training the Top layers of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WZeVeFG5jQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e84a4aff-cfe0-4df1-d50a-47f1ecb71c70"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "# initialize the training data augmentation object\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate= INIT_LR)\n",
        "#opt = SGD(lr= INIT_LR, momentum=0.9)\n",
        "#\tdecay= INIT_LR /  NUM_EPOCHS)\n",
        "\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# check to see if we are attempting to find an optimal learning rate\n",
        "# before training for the full number of epochs\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size= BATCH_SIZE),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] //  BATCH_SIZE,\n",
        "\tepochs= NUM_EPOCHS,\n",
        "\tclass_weight=classWeight,\n",
        "\tverbose=1)\n",
        "\n",
        "# evaluate the network and show a classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size= BATCH_SIZE)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names= CLASSES))\n",
        "\n",
        "# serialize the model to disk\n",
        "#print(\"[INFO] serializing network to '{}'...\".format( MODEL_PATH))\n",
        "#model.save( MODEL_PATH)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training network...\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 100 steps, validate on 1121 samples\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 69s 692ms/step - loss: 0.1553 - accuracy: 0.9394 - val_loss: 0.1299 - val_accuracy: 0.9563\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 60s 604ms/step - loss: 0.1020 - accuracy: 0.9651 - val_loss: 0.0999 - val_accuracy: 0.9643\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 60s 603ms/step - loss: 0.0822 - accuracy: 0.9692 - val_loss: 0.1134 - val_accuracy: 0.9581\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 0.0801 - accuracy: 0.9697 - val_loss: 0.1495 - val_accuracy: 0.9411\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 60s 605ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 0.1344 - val_accuracy: 0.9572\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 60s 604ms/step - loss: 0.0620 - accuracy: 0.9799 - val_loss: 0.1014 - val_accuracy: 0.9661\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 60s 603ms/step - loss: 0.0616 - accuracy: 0.9785 - val_loss: 0.0917 - val_accuracy: 0.9643\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 60s 603ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.0981 - val_accuracy: 0.9679\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0963 - val_accuracy: 0.9670\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.0414 - accuracy: 0.9852 - val_loss: 0.0958 - val_accuracy: 0.9688\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 0.0796 - val_accuracy: 0.9652\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 60s 598ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.0734 - val_accuracy: 0.9768\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0991 - val_accuracy: 0.9715\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0408 - accuracy: 0.9855 - val_loss: 0.0896 - val_accuracy: 0.9723\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 60s 597ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.1618 - val_accuracy: 0.9358\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 60s 598ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.1105 - val_accuracy: 0.9723\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.1191 - val_accuracy: 0.9643\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.1368 - val_accuracy: 0.9697\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 59s 594ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.1339 - val_accuracy: 0.9518\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 60s 599ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.1007 - val_accuracy: 0.9670\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 60s 597ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0828 - val_accuracy: 0.9715\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0883 - val_accuracy: 0.9679\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.1313 - val_accuracy: 0.9706\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 60s 597ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.1264 - val_accuracy: 0.9607\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 59s 595ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0978 - val_accuracy: 0.9697\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1132 - val_accuracy: 0.9706\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1015 - val_accuracy: 0.9715\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 59s 594ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0788 - val_accuracy: 0.9715\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.1100 - val_accuracy: 0.9741\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.1298 - val_accuracy: 0.9750\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.1705 - val_accuracy: 0.9581\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.1543 - val_accuracy: 0.9697\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.1000 - val_accuracy: 0.9768\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 60s 595ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.1347 - val_accuracy: 0.9741\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.1381 - val_accuracy: 0.9652\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1320 - val_accuracy: 0.9652\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 59s 595ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.2030 - val_accuracy: 0.9545\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.1829 - val_accuracy: 0.9411\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.1556 - val_accuracy: 0.9688\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 59s 594ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.0918 - val_accuracy: 0.9732\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 59s 594ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.2016 - val_accuracy: 0.9554\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.1388 - val_accuracy: 0.9715\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 59s 590ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.1440 - val_accuracy: 0.9706\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1109 - val_accuracy: 0.9795\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 0.1633 - val_accuracy: 0.9492\n",
            "Epoch 47/100\n",
            " 26/100 [======>.......................] - ETA: 42s - loss: 0.0147 - accuracy: 0.9956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5d6a4afb8ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassWeight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \tverbose=1)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# evaluate the network and show a classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh-jILFc-4RD"
      },
      "source": [
        "# 10. Observe the Loss Functions during the Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHzNwLZ3nW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "1a15fcb8-010f-4b15-e792-70b98c6d103c"
      },
      "source": [
        "%matplotlib inline\n",
        "#import matplotlib.pyplot as plt\n",
        "#print(H.history[\"loss\"])\n",
        "#N = np.arange(0,  NUM_EPOCHS)\n",
        "#print(N)\n",
        "#plt.plot(N,H.history[\"loss\"])\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = np.arange(0,  NUM_EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "fig = plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-917b9a3fbbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (50,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ybzgam_KCP"
      },
      "source": [
        "# 11. Observing the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxB6fgIXm6x4"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(testX[i], cmap=plt.cm.binary)\n",
        "    if testY[i][0] == 1:\n",
        "      if predictions[i][0] > 0.5:\n",
        "        plt.xlabel(\"Non-Fire\", color='green')\n",
        "      else:\n",
        "        plt.xlabel(\"Non-Fire\", color='red')\n",
        "    else:\n",
        "      if predictions[i][1] > 0.5:\n",
        "        plt.xlabel(\"Fire\", color='green')\n",
        "      else:\n",
        "        plt.xlabel(\"Fire\", color='red')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuoWnFAG_Ol9"
      },
      "source": [
        "# Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUODdKypAwPb"
      },
      "source": [
        "pip install -q pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCRhgEuoBZTk"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model1.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo8B8oA9LYtP"
      },
      "source": [
        "!cp \"/content/saved_model/my_model1.h5\" -r \"/content/drive/My Drive/SavedModels/2017EE193(2).h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEELsZBaQWuN"
      },
      "source": [
        "# Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeDvrMWaOFUE"
      },
      "source": [
        "#Loading the previous model\n",
        "!cp \"/content/drive/My Drive/SavedModels/Post9723.h5\" -r \"/content/my_model1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npxl6S51P_4L"
      },
      "source": [
        "new_model = tf.keras.models.load_model('my_model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-xFoS9qQgcC"
      },
      "source": [
        "model=new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2svk6sU_R_i"
      },
      "source": [
        "Test Data Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrA0sRDLQpIG"
      },
      "source": [
        "!unzip -q /content/drive/'My Drive'/'FinalTest.zip' -d Testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwK8k5pAB_G8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "154a4dd6-3754-4db6-f05b-47d78b0cd1e5"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import argparse\n",
        "CLASSES = [\"Non-Fire\", \"Fire\"]\n",
        "\n",
        "print(\"[INFO] loading data...\")\n",
        "fireData1 = load_dataset( '/content/Testing/FinalTest/fire')\n",
        "print(\"[INFO] Completed\")\n",
        "nonFireData1 = load_dataset( '/content/Testing/FinalTest/nonfire')\n",
        "print(\"[INFO] Completed\")\n",
        "# construct the class labels for the data\n",
        "fireLabels1 = np.ones((fireData1.shape[0],))\n",
        "nonFireLabels1 = np.zeros((nonFireData1.shape[0],))\n",
        "# stack the fire data with the non-fire data, then scale the data\n",
        "# to the range [0, 1]\n",
        "data1 = np.vstack([fireData1, nonFireData1])\n",
        "labels1 = np.hstack([fireLabels1, nonFireLabels1])\n",
        "\n",
        "\n",
        "\n",
        "data1 /= 255\n",
        "# perform one-hot encoding on the labels and account for skew in the\n",
        "# labeled data\n",
        "labels1 = to_categorical(labels1, num_classes=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading data...\n",
            "[INFO] Completed\n",
            "[INFO] Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsoXzv7dO7_V"
      },
      "source": [
        "np.shape(data1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFTVBAnI-2O"
      },
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(data1, batch_size= 64)\n",
        "print(classification_report(labels1.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names= CLASSES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nfvrYXrJJmC"
      },
      "source": [
        "model.evaluate(data1,labels1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3x54yb6DVzj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wj6lboLk2NO"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Home\" -r \"/content/Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfTGBsCwlkG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79HqidFqmtRu"
      },
      "source": [
        "fire1 = cv2.imread('/content/Test/f1.jpg')\n",
        "fire1 = cv2.resize(fire1, (128,128))\n",
        "\n",
        "fire2 = cv2.imread('/content/Test/f2.jpg')\n",
        "fire2 = cv2.resize(fire2, (128,128))\n",
        "\n",
        "non= cv2.imread('/content/Test/Non.jpg')\n",
        "non= cv2.resize(non, (128,128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NYA8Fcul8zZ"
      },
      "source": [
        "fire1=np.divide(fire1,255)\n",
        "fire2=np.divide(fire2,255)\n",
        "non=np.divide(non,255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovEg9_BVo6uT"
      },
      "source": [
        "fire1=np.expand_dims(fire1, axis=0)\n",
        "fire1=np.array(fire1, dtype=\"float32\")\n",
        "\n",
        "fire2=np.expand_dims(fire2, axis=0)\n",
        "fire2=np.array(fire2, dtype=\"float32\")\n",
        "\n",
        "non=np.expand_dims(non, axis=0)\n",
        "non=np.array(non, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8-mr85mO2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "419b14a3-57f6-490a-f83c-2b4c55a7cfa3"
      },
      "source": [
        "np.shape(fire1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEFnWJIpmbS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "d9675b20-d8da-450d-9c7d-6d6ede8fc418"
      },
      "source": [
        "fire1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00018454, 0.00016917, 0.00023068],\n",
              "        [0.00016917, 0.00015379, 0.00019992],\n",
              "        [0.00016917, 0.00015379, 0.0002153 ],\n",
              "        ...,\n",
              "        [0.00336794, 0.00347559, 0.00352172],\n",
              "        [0.00327566, 0.00336794, 0.00344483],\n",
              "        [0.0033218 , 0.00341407, 0.00347559]],\n",
              "\n",
              "       [[0.00019992, 0.00018454, 0.00024606],\n",
              "        [0.00016917, 0.00015379, 0.0002153 ],\n",
              "        [0.00015379, 0.00013841, 0.00019992],\n",
              "        ...,\n",
              "        [0.00344483, 0.00352172, 0.00356786],\n",
              "        [0.00329104, 0.00339869, 0.00344483],\n",
              "        [0.00330642, 0.00339869, 0.00346021]],\n",
              "\n",
              "       [[0.00015379, 0.00013841, 0.00018454],\n",
              "        [0.00016917, 0.00015379, 0.00018454],\n",
              "        [0.00013841, 0.00015379, 0.0002153 ],\n",
              "        ...,\n",
              "        [0.00339869, 0.00350634, 0.0035371 ],\n",
              "        [0.00335256, 0.00346021, 0.00350634],\n",
              "        [0.00336794, 0.00347559, 0.00352172]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.00084583, 0.00106113, 0.00103037],\n",
              "        [0.00079969, 0.00101499, 0.00098424],\n",
              "        [0.00086121, 0.00112265, 0.00106113],\n",
              "        ...,\n",
              "        [0.0014456 , 0.00139946, 0.00133795],\n",
              "        [0.00161476, 0.00156863, 0.00149173],\n",
              "        [0.00161476, 0.00155325, 0.00147636]],\n",
              "\n",
              "       [[0.00066128, 0.00087659, 0.00084583],\n",
              "        [0.00069204, 0.00095348, 0.00089196],\n",
              "        [0.00076894, 0.00103037, 0.00096886],\n",
              "        ...,\n",
              "        [0.00149173, 0.00149173, 0.00141484],\n",
              "        [0.00156863, 0.00152249, 0.0014456 ],\n",
              "        [0.0016609 , 0.00159938, 0.00146098]],\n",
              "\n",
              "       [[0.00069204, 0.00090734, 0.00086121],\n",
              "        [0.0007228 , 0.00095348, 0.00089196],\n",
              "        [0.00064591, 0.00087659, 0.00081507],\n",
              "        ...,\n",
              "        [0.00156863, 0.00152249, 0.0014456 ],\n",
              "        [0.00156863, 0.00153787, 0.00141484],\n",
              "        [0.0016609 , 0.00161476, 0.00149173]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO-5svAkk8p_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8246a16e-4309-4a5b-c78f-b842ad0c87ad"
      },
      "source": [
        "model(fire1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.36242422, 0.6375758 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkq8-ou0mFWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21ec9bff-b1db-4410-87eb-c9751adfab87"
      },
      "source": [
        "model.predict(non)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9979335e-01, 2.0666784e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnBnYyHJpkY8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}